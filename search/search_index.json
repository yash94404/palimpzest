{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Simple and Powerful Semantic Computation","text":"<p>Palimpzest (PZ) enables developers to write simple, powerful programs which use semantic operators (i.e. LLMs) to perform computation.</p> <p>The following code snippet sets up PZ and downloads a small datast of emails: <pre><code># setup in the terminal\n$ pip install palimpzest\n$ export OPENAI_API_KEY=\"&lt;your-api-key&gt;\"\n$ wget https://palimpzest-workloads.s3.us-east-1.amazonaws.com/emails.zip\n$ unzip emails.zip\n</code></pre> We can then execute a simple PZ program to:</p> <ol> <li>compute the <code>subject</code> and <code>date</code> of each email</li> <li>filter for emails about vacations which are sent in July</li> </ol> <p><pre><code>import palimpzest as pz\n\nemails = pz.Dataset(\"emails/\")\nemails = emails.sem_add_columns([\n    {\"name\": \"subject\", \"type\": str, \"desc\": \"the subject of the email\"},\n    {\"name\": \"date\", \"type\": str, \"desc\": \"the date the email was sent\"},\n])\nemails = emails.sem_filter(\"The email is about vacation\")\nemails = emails.sem_filter(\"The email was sent in July\")\noutput = emails.run(max_quality=True)\n\nprint(output.to_df(cols=[\"filename\", \"date\", \"subject\"]))\n</code></pre> The output from this program is shown below: <pre><code>     filename         date                  subject\n0  email4.txt   6 Jul 2001           Vacation plans\n1  email5.txt  26 Jul 2001  Vacation Days in August\n</code></pre></p>"},{"location":"#key-features-of-pz","title":"Key Features of PZ","text":"<p>There are a few features of this program which are worth highlighting:</p> <ol> <li>The programmer creates a <code>pz.Dataset</code> from the directory of emails and defines a series of semantic computations on that dataset:<ul> <li><code>sem_add_columns()</code> specifies a set of fields which PZ must compute</li> <li><code>sem_filter()</code> selects for emails which satisfy the natural language filter</li> </ul> </li> <li>The user does not specify how the computation should be performed -- they simply declare what they want PZ to compute<ul> <li>This is what makes PZ declarative</li> </ul> </li> <li>Under the hood, PZ's optimizer determines the best way to execute each semantic operator<ul> <li>In this example, PZ optimizes for output quality because the user sets <code>max_quality=True</code></li> </ul> </li> <li>The <code>output</code> is not generated until the call to <code>emails.run()</code><ul> <li>i.e. PZ uses lazy evaluation</li> </ul> </li> </ol>"},{"location":"#declarative-optimization-for-ai","title":"Declarative Optimization for AI","text":"<p>The core philosophy behind PZ is that programmers should simply specify the high-level logic of their AI programs while offloading much of the performance tuning to a powerful optimizer. Of course, users still have the ability to fully control their program, and can override and assist the optimizer (if needed) to get the best possible performance.</p> <p>This email processing example only showcases a small set of the semantic operators implemented in PZ. Other operators include:</p> <ul> <li><code>retrieve()</code> which takes a vector database and a search string as input and retrieves the most relevant entries from the database</li> <li><code>add_columns()</code> and <code>filter()</code> which are the non-semantic equivalents of <code>sem_add_columns()</code> and <code>sem_filter()</code></li> <li><code>groupby()</code>, <code>count()</code>, <code>average()</code>, <code>limit()</code>, and <code>project()</code> which mirror their implementations in frameworks like Pandas and Spark.</li> </ul>"},{"location":"#join-our-community","title":"Join our community","text":"<p>We strongly encourage you to join our Discord server where we are happy to help you get started with PZ.</p>"},{"location":"#whats-next","title":"What's Next?","text":"<p>The rest of our Getting Started section will:</p> <ol> <li>Help you install PZ</li> <li>Explore more of PZ's features in our Quick Start Tutorial</li> <li>Give you an overview of our User Guides which discuss features of PZ in more depth</li> </ol>"},{"location":"chat-demo/","title":"Chat Demo","text":"<p>To access our chat demo please visit our demo webpage for PalimpChat.</p> <p></p>"},{"location":"community/","title":"Join the Community","text":"<p>We are actively hacking on PZ and would love to have you join our community: </p> <p>Our Discord server is the best place to:</p> <ul> <li>Get help with your PZ program(s)</li> <li>Give feedback to the maintainers</li> <li>Discuss the future direction(s) of the project</li> <li>Discuss anything related to data processing with LLMs!</li> </ul> <p>We are eager to learn more about your workloads and use cases, and will take them into consideration in planning our future roadmap.</p>"},{"location":"research/","title":"Research Papers","text":"<p>Palimpzest has been the source of a number of research papers. Here is a timeline of the papers along with their citations.</p>"},{"location":"research/#winter-2025","title":"Winter 2025","text":"<p>PalimpChat: A Chat Interface for Palimpzest [arXiv]</p> <p>Abstract</p> <p>Thanks to the advances in generative architectures and large language models, data scientists can now code pipelines of machine-learning operations to process large collections of unstructured data. Recent progress has seen the rise of declarative AI frameworks (e.g., Palimpzest, Lotus, and DocETL) to build optimized and increasingly complex pipelines, but these systems often remain accessible only to expert programmers. In this demonstration, we present PalimpChat, a chat-based interface to Palimpzest that bridges this gap by letting users create and run sophisticated AI pipelines through natural language alone. By integrating Archytas, a ReAct-based reasoning agent, and Palimpzest's suite of relational and LLM-based operators, PalimpChat provides a practical illustration of how a chat interface can make declarative AI frameworks truly accessible to non-experts.</p> <p>Our demo system is publicly available online. At SIGMOD'25, participants can explore three real-world scenarios--scientific discovery, legal discovery, and real estate search--or apply PalimpChat to their own datasets. In this paper, we focus on how PalimpChat, supported by the Palimpzest optimizer, simplifies complex AI workflows such as extracting and analyzing biomedical data.</p> <pre><code>@misc{liu2025palimpchatdeclarativeinteractiveai,\n    title={PalimpChat: Declarative and Interactive AI analytics}, \n    author={Chunwei Liu and Gerardo Vitagliano and Brandon Rose and Matt Prinz and David Andrew Samson and Michael Cafarella},\n    year={2025},\n    eprint={2502.03368},\n    archivePrefix={arXiv},\n    primaryClass={cs.AI},\n    url={https://arxiv.org/abs/2502.03368}, \n}\n</code></pre> <p>SciVar: Enabling Optimized Scientific Discovery in 16 Lines of Palimpzest Code [arXiv]</p> <p>Abstract</p> <p>The global output of academic publications exceeds 5 million articles per year, making it difficult for humans to keep up with even a tiny fraction of scientific output. We need methods to navigate and interpret the artifacts -- texts, graphs, charts, code, models, and datasets -- that make up the literature. This paper evaluates various methods for extracting mathematical model variables from epidemiological studies, such as \"infection rate (\u03b1)\", \"recovery rate (\u03b3)\", and \"mortality rate (\u03bc)\". Variable extraction appears to be a basic task, but plays a pivotal role in recovering models from scientific literature. Once extracted, we can use these variables for automatic mathematical modeling, simulation, and replication of published results.</p> <p>We introduce a benchmark dataset comprising manually-annotated variable descriptions and variable values extracted from scientific papers. Based on this dataset, we present several baseline methods for variable extraction based on Large Language Models (LLMs) and rule-based information extraction systems. Our analysis shows that LLM-based solutions perform the best. Despite the incremental benefits of combining rule-based extraction outputs with LLMs, the leap in performance attributed to the transfer-learning and instruction-tuning capabilities of LLMs themselves is far more significant. This investigation demonstrates the potential of LLMs to enhance automatic comprehension of scientific artifacts and for automatic model recovery and simulation.</p> <pre><code>@misc{liu2024variableextractionmodelrecovery,\n    title={Variable Extraction for Model Recovery in Scientific Literature}, \n    author={Chunwei Liu and Enrique Noriega-Atala and Adarsh Pyarelal and Clayton T Morrison and Mike Cafarella},\n    year={2024},\n    eprint={2411.14569},\n    archivePrefix={arXiv},\n    primaryClass={cs.IR},\n    url={https://arxiv.org/abs/2411.14569}, \n}\n</code></pre>"},{"location":"research/#spring-2024","title":"Spring 2024","text":"<p>Palimpzest: Optimizing AI-Powered Analytics with Declarative Query Processing [CIDR'25] [arXiv]</p> <p>Abstract</p> <p>A long-standing goal of data management systems has been to build systems which can compute quantitative insights over large collections of unstructured data in a cost-effective manner. Until recently, it was difficult and expensive to extract facts from company documents, data from scientific papers, or metrics from image and video corpora. Today\u2019s models can accomplish these tasks with high accuracy. However, a programmer who wants to answer a substantive AI-powered query must orchestrate large numbers of models, prompts, and data operations. In this paper, we present PALIMPZEST, a system that enables programmers to pose AI-powered analytical queries over arbitrary collections of unstructured data in a simple declarative language. The system uses a cost optimization framework\u2014which explores the search space of AI models, prompting techniques, and related foundation model optimizations. PALIMPZEST implements the query while navigating the trade-offs between runtime, financial cost, and output data quality. We introduce a novel language for AI-powered analytics tasks, the optimization methods that PALIMPZEST uses, and the prototype system itself. We evaluate PALIMPZEST on a real-world workload. Our system produces plans that are up to 3.3 x faster and 2.9 x cheaper than a baseline method when using a singlethread setup, while also achieving superior F1-scores. PALIMPZEST applies its optimizations automatically, requiring no additional work from the user.</p> <pre><code>@inproceedings{palimpzestCIDR,\n    title={Palimpzest: Optimizing AI-Powered Analytics with Declarative Query Processing},\n    author={Liu, Chunwei and Russo, Matthew and Cafarella, Michael and Cao, Lei and Chen, Peter Baile and Chen, Zui and Franklin, Michael and Kraska, Tim and Madden, Samuel and Shahout, Rana and others},\n    booktitle = {Proceedings of the {{Conference}} on {{Innovative Database Research}} ({{CIDR}})},\n    date = 2025,\n}\n</code></pre>"},{"location":"api/dataset/","title":"Dataset","text":"<p>A Dataset is the intended abstraction for programmers to interact with when writing PZ programs.</p> <p>Users instantiate a Dataset by specifying a <code>source</code> that either points to a DataReader or an existing Dataset. Users can then perform computations on the Dataset in a lazy fashion by leveraging functions such as <code>filter</code>, <code>sem_filter</code>, <code>sem_add_columns</code>, <code>aggregate</code>, etc. Underneath the hood, each of these operations creates a new Dataset. As a result, the Dataset defines a lineage of computation.</p>"},{"location":"api/dataset/#palimpzest.sets.Dataset.add_columns","title":"add_columns","text":"<pre><code>add_columns(\n    udf: Callable,\n    cols: list[dict] | type[Schema],\n    cardinality: Cardinality = Cardinality.ONE_TO_ONE,\n    depends_on: str | list[str] | None = None,\n    desc: str = \"Add new columns via UDF\",\n) -&gt; Dataset\n</code></pre> <p>Add new columns by specifying UDFs.</p> <p>Examples:</p> <p>add_columns(     udf=compute_personal_greeting,     cols=[         {'name': 'greeting', 'desc': 'The greeting message', 'type': str},         {'name': 'age', 'desc': 'The age of the person', 'type': int},         {'name': 'full_name', 'desc': 'The name of the person', 'type': str},     ] )</p>"},{"location":"api/dataset/#palimpzest.sets.Dataset.average","title":"average","text":"<pre><code>average() -&gt; Dataset\n</code></pre> <p>Apply an average aggregation to this set</p>"},{"location":"api/dataset/#palimpzest.sets.Dataset.count","title":"count","text":"<pre><code>count() -&gt; Dataset\n</code></pre> <p>Apply a count aggregation to this set</p>"},{"location":"api/dataset/#palimpzest.sets.Dataset.filter","title":"filter","text":"<pre><code>filter(_filter: Callable, depends_on: str | list[str] | None = None) -&gt; Dataset\n</code></pre> <p>Add a user defined function as a filter to the Set. This filter will possibly restrict the items that are returned later.</p>"},{"location":"api/dataset/#palimpzest.sets.Dataset.limit","title":"limit","text":"<pre><code>limit(n: int) -&gt; Dataset\n</code></pre> <p>Limit the set size to no more than n rows</p>"},{"location":"api/dataset/#palimpzest.sets.Dataset.project","title":"project","text":"<pre><code>project(project_cols: list[str] | str) -&gt; Dataset\n</code></pre> <p>Project the Set to only include the specified columns.</p>"},{"location":"api/dataset/#palimpzest.sets.Dataset.retrieve","title":"retrieve","text":"<pre><code>retrieve(\n    index,\n    search_func: Callable,\n    search_attr: str,\n    output_attr: str,\n    output_attr_desc: str,\n    k=-1,\n) -&gt; Dataset\n</code></pre> <p>Retrieve the top k nearest neighbors of the value of the <code>search_attr</code> from the index and stores it in the <code>output_attr</code> field. The output schema is a union of the current schema and the <code>output_attr</code> with type ListField(StringField). <code>search_func</code> is a function of type (index, query: str | list(str), k: int) -&gt; list[str]. It should implement the lookup logic for the index and return the top k results. The value of the <code>search_attr</code> field is used as the query to lookup in the index. The results are stored in the <code>output_attr</code> field. <code>output_attr_desc</code> is the description of the <code>output_attr</code> field.</p>"},{"location":"api/dataset/#palimpzest.sets.Dataset.run","title":"run","text":"<pre><code>run(config: QueryProcessorConfig | None = None, **kwargs)\n</code></pre> <p>Invoke the QueryProcessor to execute the query. <code>kwargs</code> will be applied to the QueryProcessorConfig.</p>"},{"location":"api/dataset/#palimpzest.sets.Dataset.sem_add_columns","title":"sem_add_columns","text":"<pre><code>sem_add_columns(\n    cols: list[dict] | type[Schema],\n    cardinality: Cardinality = Cardinality.ONE_TO_ONE,\n    depends_on: str | list[str] | None = None,\n    desc: str = \"Add new columns via semantic reasoning\",\n) -&gt; Dataset\n</code></pre> <p>Add new columns by specifying the column names, descriptions, and types. The column will be computed during the execution of the Dataset. Example:     sem_add_columns(         [{'name': 'greeting', 'desc': 'The greeting message', 'type': str},          {'name': 'age', 'desc': 'The age of the person', 'type': int},          {'name': 'full_name', 'desc': 'The name of the person', 'type': str}]     )</p>"},{"location":"api/dataset/#palimpzest.sets.Dataset.sem_filter","title":"sem_filter","text":"<pre><code>sem_filter(_filter: str, depends_on: str | list[str] | None = None) -&gt; Dataset\n</code></pre> <p>Add a natural language description of a filter to the Set. This filter will possibly restrict the items that are returned later.</p>"},{"location":"api/overview/","title":"Overview","text":"<p>This section contains the full documentation for the major classes and methods in PZ.</p> <p>Our documentation is separated into the following categories:</p> <ul> <li><code>Dataset</code>: <code>pz.Dataset</code> and all user-facing operator methods.</li> <li><code>Data</code>: all classes involved in reading, representing, and storing data in PZ.</li> <li><code>Operators</code>: the physical operators used internally by PZ.</li> <li><code>Optimization</code>: all classes involved with optimization.</li> </ul> <p>These pages are still a work in progress, so please reach out to us on Discord if there is missing documentation that you would like to see!</p>"},{"location":"api/data/datareader/","title":"DataReader","text":"<p>The <code>DataReader</code> is a base class for which may be used to generate data that is processed by PZ.</p> <p>Subclasses of the (abstract) <code>DataReader</code> class must implement two methods:</p> <ul> <li><code>__len__()</code>: which returns the number of elements in the data source</li> <li><code>__getitem__(idx: int)</code>: which takes in an <code>idx</code> and returns the element at that index</li> </ul>"},{"location":"api/data/datareader/#palimpzest.core.data.datareaders.DataReader.__init__","title":"__init__","text":"<pre><code>__init__(schema: type[Schema] | list[dict]) -&gt; None\n</code></pre> <p>Constructor for the <code>DataReader</code> class.</p> <p>Parameters:</p> <ul> <li> <code>schema</code>               (<code>Schema | list[dict]</code>)           \u2013            <p>The output schema of the records returned by the DataReader</p> </li> </ul>"},{"location":"api/data/datareader/#palimpzest.core.data.datareaders.DataReader.__len__","title":"__len__  <code>abstractmethod</code>","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Returns the number of items in the data reader.</p>"},{"location":"api/data/datareader/#palimpzest.core.data.datareaders.DataReader.__getitem__","title":"__getitem__  <code>abstractmethod</code>","text":"<pre><code>__getitem__(idx: int) -&gt; dict\n</code></pre> <p>Returns a single item from the data reader at the given index.</p> <p>Parameters:</p> <ul> <li> <code>idx</code>               (<code>int</code>)           \u2013            <p>The index of the item to return</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>dict</code> )          \u2013            <p>A dictionary representing the item at the given index. The dictionary   keys (i.e. fields) should match the fields specified in the schema of the   data source, and the values should be the values associated with those fields.</p> <pre><code># Example return value\n{\"field1\": value1, \"field2\": value2, ...}\n</code></pre> </li> </ul>"},{"location":"api/data/datarecord/","title":"DataRecord","text":"<p>A DataRecord is a single record of data matching some Schema.</p>"},{"location":"api/data/datarecord/#palimpzest.core.elements.records.DataRecord.from_df","title":"from_df  <code>staticmethod</code>","text":"<pre><code>from_df(df: DataFrame, schema: Schema | None = None) -&gt; list[DataRecord]\n</code></pre> <p>Create a list of DataRecords from a pandas DataFrame</p> <p>Parameters:</p> <ul> <li> <code>df</code>               (<code>DataFrame</code>)           \u2013            <p>Input DataFrame</p> </li> <li> <code>schema</code>               (<code>Schema</code>, default:                   <code>None</code> )           \u2013            <p>Schema for the DataRecords. If None, will be derived from DataFrame  </p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[DataRecord]</code>           \u2013            <p>list[DataRecord]: List of DataRecord instances</p> </li> </ul>"},{"location":"api/data/datarecord/#palimpzest.core.elements.records.DataRecord.to_dict","title":"to_dict","text":"<pre><code>to_dict(include_bytes: bool = True, project_cols: list[str] | None = None)\n</code></pre> <p>Return a dictionary representation of this DataRecord</p>"},{"location":"api/data/datarecord/#palimpzest.core.elements.records.DataRecord.to_json_str","title":"to_json_str","text":"<pre><code>to_json_str(include_bytes: bool = True, project_cols: list[str] | None = None)\n</code></pre> <p>Return a JSON representation of this DataRecord</p>"},{"location":"api/data/datarecordcollection/","title":"DataRecordCollection","text":"<p>A DataRecordCollection contains a list of DataRecords.</p> <p>This is a wrapper class for list[DataRecord] to support more advanced features for output of execute().</p> <p>The difference between DataRecordSet and DataRecordCollection </p> Goal <p>DataRecordSet is a set of DataRecords that share the same schema, same parent_id, and same source_idx. DataRecordCollection is a general wrapper for list[DataRecord].</p> Usage <p>DataRecordSet is used for the output of executing an operator. DataRecordCollection is used for the output of executing a query, we definitely could extend it to support more advanced features for output of execute().</p>"},{"location":"api/data/datarecordcollection/#palimpzest.core.elements.records.DataRecordCollection.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; Generator[DataRecord]\n</code></pre> <p>Allow iterating directly over the data records</p>"},{"location":"api/data/datarecordcollection/#palimpzest.core.elements.records.DataRecordCollection.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>Return the number of records in the collection</p>"},{"location":"api/operators/aggregate/","title":"Aggregate","text":""},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.AggregateOp","title":"AggregateOp","text":"<p>               Bases: <code>PhysicalOperator</code></p> <p>Aggregate operators accept a list of candidate DataRecords as input to their call methods. Thus, we use a slightly modified abstract base class for these operators.</p>"},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.AggregateOp.__call__","title":"__call__","text":"<pre><code>__call__(candidates: DataRecordSet) -&gt; DataRecordSet\n</code></pre>"},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.ApplyGroupByOp","title":"ApplyGroupByOp","text":"<p>               Bases: <code>AggregateOp</code></p> <p>Implementation of a GroupBy operator. This operator groups records by a set of fields and applies a function to each group. The group_by_sig object contains the fields to group by and the aggregation functions to apply to each group.</p>"},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.ApplyGroupByOp.__init__","title":"__init__","text":"<pre><code>__init__(group_by_sig: GroupBySig, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.ApplyGroupByOp.__call__","title":"__call__","text":"<pre><code>__call__(candidates: DataRecordSet) -&gt; DataRecordSet\n</code></pre>"},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.AverageAggregateOp","title":"AverageAggregateOp","text":"<p>               Bases: <code>AggregateOp</code></p>"},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.AverageAggregateOp.__init__","title":"__init__","text":"<pre><code>__init__(agg_func: AggFunc, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.AverageAggregateOp.__call__","title":"__call__","text":"<pre><code>__call__(candidates: DataRecordSet) -&gt; DataRecordSet\n</code></pre>"},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.CountAggregateOp","title":"CountAggregateOp","text":"<p>               Bases: <code>AggregateOp</code></p>"},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.CountAggregateOp.__init__","title":"__init__","text":"<pre><code>__init__(agg_func: AggFunc, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/aggregate/#palimpzest.query.operators.aggregate.CountAggregateOp.__call__","title":"__call__","text":"<pre><code>__call__(candidates: DataRecordSet) -&gt; DataRecordSet\n</code></pre>"},{"location":"api/operators/limit/","title":"Limit","text":""},{"location":"api/operators/limit/#palimpzest.query.operators.limit.LimitScanOp","title":"LimitScanOp","text":"<p>               Bases: <code>PhysicalOperator</code></p>"},{"location":"api/operators/limit/#palimpzest.query.operators.limit.LimitScanOp.__init__","title":"__init__","text":"<pre><code>__init__(limit: int, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/limit/#palimpzest.query.operators.limit.LimitScanOp.__call__","title":"__call__","text":"<pre><code>__call__(candidate: DataRecord) -&gt; DataRecordSet\n</code></pre>"},{"location":"api/operators/logical/","title":"Logical","text":"<p>This page contains the API documentation for all of the logical operators in PZ.</p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.LogicalOperator","title":"LogicalOperator","text":"<p>A logical operator is an operator that operates on Sets.</p> <p>Right now it can be one of: - BaseScan (scans data from DataReader) - CacheScan (scans cached Set) - FilteredScan (scans input Set and applies filter) - ConvertScan (scans input Set and converts it to new Schema) - LimitScan (scans up to N records from a Set) - GroupByAggregate (applies a group by on the Set) - Aggregate (applies an aggregation on the Set) - RetrieveScan (fetches documents from a provided input for a given query)</p> <p>Every logical operator must declare the get_logical_id_params() and get_logical_op_params() methods, which return dictionaries of parameters that are used to compute the logical op id and to implement the logical operator (respectively).</p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.LogicalOperator.__init__","title":"__init__","text":"<pre><code>__init__(output_schema: Schema, input_schema: Schema | None = None)\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.LogicalOperator.get_logical_id_params","title":"get_logical_id_params","text":"<pre><code>get_logical_id_params() -&gt; dict\n</code></pre> <p>Returns a dictionary mapping of logical operator parameters which are relevant for computing the logical operator id.</p> <p>NOTE: Should be overriden by subclasses to include class-specific parameters. NOTE: input_schema and output_schema are not included in the id params because       they depend on how the Optimizer orders operations.</p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.LogicalOperator.get_logical_op_params","title":"get_logical_op_params","text":"<pre><code>get_logical_op_params() -&gt; dict\n</code></pre> <p>Returns a dictionary mapping of logical operator parameters which may be used to implement a physical operator associated with this logical operation.</p> <p>NOTE: Should be overriden by subclasses to include class-specific parameters.</p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.Aggregate","title":"Aggregate","text":"<p>               Bases: <code>LogicalOperator</code></p> <p>Aggregate is a logical operator that applies an aggregation to the input set and yields a single result. This is a base class that has to be further specialized to implement specific aggregation functions.</p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.Aggregate.__init__","title":"__init__","text":"<pre><code>__init__(\n    agg_func: AggFunc, target_cache_id: str | None = None, *args, **kwargs\n)\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.Aggregate.get_logical_id_params","title":"get_logical_id_params","text":"<pre><code>get_logical_id_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.Aggregate.get_logical_op_params","title":"get_logical_op_params","text":"<pre><code>get_logical_op_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.BaseScan","title":"BaseScan","text":"<p>               Bases: <code>LogicalOperator</code></p> <p>A BaseScan is a logical operator that represents a scan of a particular data source.</p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.BaseScan.__init__","title":"__init__","text":"<pre><code>__init__(datareader: DataReader, output_schema: Schema)\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.BaseScan.get_logical_id_params","title":"get_logical_id_params","text":"<pre><code>get_logical_id_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.BaseScan.get_logical_op_params","title":"get_logical_op_params","text":"<pre><code>get_logical_op_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.CacheScan","title":"CacheScan","text":"<p>               Bases: <code>LogicalOperator</code></p> <p>A CacheScan is a logical operator that represents a scan of a cached Set.</p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.CacheScan.__init__","title":"__init__","text":"<pre><code>__init__(datareader: DataReader, output_schema: Schema)\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.CacheScan.get_logical_id_params","title":"get_logical_id_params","text":"<pre><code>get_logical_id_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.CacheScan.get_logical_op_params","title":"get_logical_op_params","text":"<pre><code>get_logical_op_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.ConvertScan","title":"ConvertScan","text":"<p>               Bases: <code>LogicalOperator</code></p> <p>A ConvertScan is a logical operator that represents a scan of a particular data source, with conversion applied.</p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.ConvertScan.__init__","title":"__init__","text":"<pre><code>__init__(\n    cardinality: Cardinality = Cardinality.ONE_TO_ONE,\n    udf: Callable | None = None,\n    depends_on: list[str] | None = None,\n    desc: str | None = None,\n    target_cache_id: str | None = None,\n    *args,\n    **kwargs,\n)\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.ConvertScan.get_logical_id_params","title":"get_logical_id_params","text":"<pre><code>get_logical_id_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.ConvertScan.get_logical_op_params","title":"get_logical_op_params","text":"<pre><code>get_logical_op_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.FilteredScan","title":"FilteredScan","text":"<p>               Bases: <code>LogicalOperator</code></p> <p>A FilteredScan is a logical operator that represents a scan of a particular data source, with filters applied.</p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.FilteredScan.__init__","title":"__init__","text":"<pre><code>__init__(\n    filter: Filter,\n    depends_on: list[str] | None = None,\n    target_cache_id: str | None = None,\n    *args,\n    **kwargs,\n)\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.FilteredScan.get_logical_id_params","title":"get_logical_id_params","text":"<pre><code>get_logical_id_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.FilteredScan.get_logical_op_params","title":"get_logical_op_params","text":"<pre><code>get_logical_op_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.GroupByAggregate","title":"GroupByAggregate","text":"<p>               Bases: <code>LogicalOperator</code></p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.GroupByAggregate.__init__","title":"__init__","text":"<pre><code>__init__(\n    group_by_sig: GroupBySig,\n    target_cache_id: str | None = None,\n    *args,\n    **kwargs,\n)\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.GroupByAggregate.get_logical_id_params","title":"get_logical_id_params","text":"<pre><code>get_logical_id_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.GroupByAggregate.get_logical_op_params","title":"get_logical_op_params","text":"<pre><code>get_logical_op_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.LimitScan","title":"LimitScan","text":"<p>               Bases: <code>LogicalOperator</code></p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.LimitScan.__init__","title":"__init__","text":"<pre><code>__init__(limit: int, target_cache_id: str | None = None, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.LimitScan.get_logical_id_params","title":"get_logical_id_params","text":"<pre><code>get_logical_id_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.LimitScan.get_logical_op_params","title":"get_logical_op_params","text":"<pre><code>get_logical_op_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.Project","title":"Project","text":"<p>               Bases: <code>LogicalOperator</code></p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.Project.__init__","title":"__init__","text":"<pre><code>__init__(\n    project_cols: list[str], target_cache_id: str | None = None, *args, **kwargs\n)\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.Project.get_logical_id_params","title":"get_logical_id_params","text":"<pre><code>get_logical_id_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.Project.get_logical_op_params","title":"get_logical_op_params","text":"<pre><code>get_logical_op_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.RetrieveScan","title":"RetrieveScan","text":"<p>               Bases: <code>LogicalOperator</code></p> <p>A RetrieveScan is a logical operator that represents a scan of a particular data source, with a convert-like retrieve applied.</p>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.RetrieveScan.__init__","title":"__init__","text":"<pre><code>__init__(\n    index,\n    search_func,\n    search_attr,\n    output_attr,\n    k,\n    target_cache_id: str = None,\n    *args,\n    **kwargs,\n)\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.RetrieveScan.get_logical_id_params","title":"get_logical_id_params","text":"<pre><code>get_logical_id_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/logical/#palimpzest.query.operators.logical.RetrieveScan.get_logical_op_params","title":"get_logical_op_params","text":"<pre><code>get_logical_op_params() -&gt; dict\n</code></pre>"},{"location":"api/operators/physical/","title":"Physical","text":""},{"location":"api/operators/physical/#palimpzest.query.operators.physical.PhysicalOperator","title":"PhysicalOperator","text":"<p>All implemented physical operators should inherit from this class. In order for the Optimizer to consider using a physical operator for a given logical operation, the user must also write an ImplementationRule.</p>"},{"location":"api/operators/physical/#palimpzest.query.operators.physical.PhysicalOperator.__init__","title":"__init__","text":"<pre><code>__init__(\n    output_schema: Schema,\n    input_schema: Schema | None = None,\n    depends_on: list[str] | None = None,\n    logical_op_id: str | None = None,\n    logical_op_name: str | None = None,\n    target_cache_id: str | None = None,\n    verbose: bool = False,\n    *args,\n    **kwargs,\n) -&gt; None\n</code></pre>"},{"location":"api/operators/physical/#palimpzest.query.operators.physical.PhysicalOperator.get_id_params","title":"get_id_params","text":"<pre><code>get_id_params() -&gt; dict\n</code></pre> <p>Returns a dictionary mapping of physical operator parameters which are relevant for computing the physical operator id.</p> <p>NOTE: Should be overriden by subclasses to include class-specific parameters. NOTE: input_schema and output_schema are not included in the id params by default,       because they may depend on the order of operations chosen by the Optimizer.       This is particularly true for convert operations, where the output schema       is now the union of the input and output schemas of the logical operator.</p>"},{"location":"api/operators/physical/#palimpzest.query.operators.physical.PhysicalOperator.get_op_params","title":"get_op_params","text":"<pre><code>get_op_params() -&gt; dict\n</code></pre> <p>Returns a dictionary mapping of physical operator parameters which may be used to create a copy of this physical operation.</p> <p>NOTE: Should be overriden by subclasses to include class-specific parameters.</p>"},{"location":"api/operators/retrieve/","title":"Retrieve","text":""},{"location":"api/operators/retrieve/#palimpzest.query.operators.retrieve.RetrieveOp","title":"RetrieveOp","text":"<p>               Bases: <code>PhysicalOperator</code></p>"},{"location":"api/operators/retrieve/#palimpzest.query.operators.retrieve.RetrieveOp.__init__","title":"__init__","text":"<pre><code>__init__(index, search_func, search_attr, output_attr, k, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/retrieve/#palimpzest.query.operators.retrieve.RetrieveOp.__call__","title":"__call__","text":"<pre><code>__call__(candidate: DataRecord) -&gt; DataRecordSet\n</code></pre>"},{"location":"api/operators/scan/","title":"Scan","text":""},{"location":"api/operators/scan/#palimpzest.query.operators.scan.ScanPhysicalOp","title":"ScanPhysicalOp","text":"<p>               Bases: <code>PhysicalOperator</code>, <code>ABC</code></p> <p>Physical operators which implement DataReaders require slightly more information in order to accurately compute naive cost estimates. Thus, we use a slightly modified abstract base class for these operators.</p>"},{"location":"api/operators/scan/#palimpzest.query.operators.scan.ScanPhysicalOp.__init__","title":"__init__","text":"<pre><code>__init__(datareader: DataReader, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/scan/#palimpzest.query.operators.scan.ScanPhysicalOp.__call__","title":"__call__","text":"<pre><code>__call__(idx: int) -&gt; DataRecordSet\n</code></pre> <p>This function invokes <code>self.datareader.__getitem__</code> on the given <code>idx</code> to retrieve the next data item. It then returns this item as a DataRecord wrapped in a DataRecordSet.</p>"},{"location":"api/operators/scan/#palimpzest.query.operators.scan.MarshalAndScanDataOp","title":"MarshalAndScanDataOp","text":"<p>               Bases: <code>ScanPhysicalOp</code></p>"},{"location":"api/operators/scan/#palimpzest.query.operators.scan.CacheScanDataOp","title":"CacheScanDataOp","text":"<p>               Bases: <code>ScanPhysicalOp</code></p>"},{"location":"api/operators/convert/code-synthesis-convert/","title":"CodeSynthesisConvert","text":""},{"location":"api/operators/convert/code-synthesis-convert/#palimpzest.query.operators.code_synthesis_convert.CodeSynthesisConvert","title":"CodeSynthesisConvert","text":"<p>               Bases: <code>LLMConvert</code></p>"},{"location":"api/operators/convert/code-synthesis-convert/#palimpzest.query.operators.code_synthesis_convert.CodeSynthesisConvert.__init__","title":"__init__","text":"<pre><code>__init__(\n    exemplar_generation_model: Model = Model.GPT_4o,\n    code_synth_model: Model = Model.GPT_4o,\n    conventional_fallback_model: Model = Model.GPT_4o_MINI,\n    *args,\n    **kwargs,\n)\n</code></pre>"},{"location":"api/operators/convert/code-synthesis-convert/#palimpzest.query.operators.code_synthesis_convert.CodeSynthesisConvert.is_image_conversion","title":"is_image_conversion","text":"<pre><code>is_image_conversion()\n</code></pre> <p>Code synthesis is disallowed on image conversions, so this must be False.</p>"},{"location":"api/operators/convert/code-synthesis-convert/#palimpzest.query.operators.code_synthesis_convert.CodeSynthesisConvert.convert","title":"convert","text":"<pre><code>convert(\n    candidate: DataRecord, fields: list[str] | None = None\n) -&gt; tuple[dict[FieldName, list[Any] | None], GenerationStats]\n</code></pre>"},{"location":"api/operators/convert/convert/","title":"Base","text":""},{"location":"api/operators/convert/convert/#palimpzest.query.operators.convert.ConvertOp","title":"ConvertOp","text":"<p>               Bases: <code>PhysicalOperator</code>, <code>ABC</code></p>"},{"location":"api/operators/convert/convert/#palimpzest.query.operators.convert.ConvertOp.__init__","title":"__init__","text":"<pre><code>__init__(\n    cardinality: Cardinality = Cardinality.ONE_TO_ONE,\n    udf: Callable | None = None,\n    desc: str | None = None,\n    *args,\n    **kwargs,\n)\n</code></pre>"},{"location":"api/operators/convert/convert/#palimpzest.query.operators.convert.ConvertOp.__call__","title":"__call__","text":"<pre><code>__call__(candidate: DataRecord) -&gt; DataRecordSet\n</code></pre> <p>This method converts an input DataRecord into an output DataRecordSet. The output DataRecordSet contains the DataRecord(s) output by the operator's convert() method and their corresponding RecordOpStats objects. Some subclasses may override this __call__method to implement their own custom logic.</p>"},{"location":"api/operators/convert/convert/#palimpzest.query.operators.convert.ConvertOp.is_image_conversion","title":"is_image_conversion  <code>abstractmethod</code>","text":"<pre><code>is_image_conversion() -&gt; bool\n</code></pre> <p>Return True if the convert operation processes an image, False otherwise.</p>"},{"location":"api/operators/convert/convert/#palimpzest.query.operators.convert.ConvertOp.convert","title":"convert  <code>abstractmethod</code>","text":"<pre><code>convert(\n    candidate: DataRecord, fields: list[str]\n) -&gt; tuple[dict[FieldName, list[Any] | None], GenerationStats]\n</code></pre> <p>This abstract method will be implemented by subclasses of ConvertOp to process the input DataRecord and generate the value(s) for each of the specified fields. If the convert operator is a one-to-many convert, then each field will have a corresponding list of output values. The dictionary mapping each generated field to its (list of) value(s) is returned along with the GenerationStats object.</p> <p>For example, if the input DataRecord (i.e. <code>candidate</code>) contains the contents of a scientific paper, and the convert operation is supposed to extract the name and affiliation of each author into its own DataRecord, then the output could be:</p> <p>({\"author\": [\"Jane Smith\", \"John Doe\"], \"affiliation\": [\"MIT\", \"Stanford University\"]}, GenerationStats(...))</p> <p>Even if the convert operation is a one-to-one convert (i.e. it always generates one output DataRecord for each input DataRecord), the output should still map each field to a singleton list containing its value.</p> <p>A post-condition of this method is that every field in <code>fields</code> must be present in the output dictionary. If there is an error in generating a field, then the value for that field must be None.</p>"},{"location":"api/operators/convert/critique-and-refine-convert/","title":"CriticAndRefineConvert","text":""},{"location":"api/operators/convert/critique-and-refine-convert/#palimpzest.query.operators.critique_and_refine_convert.CriticAndRefineConvert","title":"CriticAndRefineConvert","text":"<p>               Bases: <code>LLMConvert</code></p>"},{"location":"api/operators/convert/critique-and-refine-convert/#palimpzest.query.operators.critique_and_refine_convert.CriticAndRefineConvert.__init__","title":"__init__","text":"<pre><code>__init__(critic_model: Model, refine_model: Model, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/convert/critique-and-refine-convert/#palimpzest.query.operators.critique_and_refine_convert.CriticAndRefineConvert.convert","title":"convert","text":"<pre><code>convert(\n    candidate: DataRecord, fields: list[str]\n) -&gt; tuple[dict[FieldName, list[Any]], GenerationStats]\n</code></pre>"},{"location":"api/operators/convert/llm-convert/","title":"LLMConvert","text":""},{"location":"api/operators/convert/llm-convert/#palimpzest.query.operators.convert.LLMConvert","title":"LLMConvert","text":"<p>               Bases: <code>ConvertOp</code></p> <p>This is the base class for convert operations which use an LLM to generate the output fields.</p>"},{"location":"api/operators/convert/llm-convert/#palimpzest.query.operators.convert.LLMConvert.__init__","title":"__init__","text":"<pre><code>__init__(\n    model: Model,\n    prompt_strategy: PromptStrategy = PromptStrategy.COT_QA,\n    *args,\n    **kwargs,\n)\n</code></pre>"},{"location":"api/operators/convert/llm-convert/#palimpzest.query.operators.convert.LLMConvertConventional","title":"LLMConvertConventional","text":"<p>               Bases: <code>LLMConvert</code></p>"},{"location":"api/operators/convert/llm-convert/#palimpzest.query.operators.convert.LLMConvertConventional.convert","title":"convert","text":"<pre><code>convert(\n    candidate: DataRecord, fields: list[str]\n) -&gt; tuple[dict[FieldName, list[Any]], GenerationStats]\n</code></pre>"},{"location":"api/operators/convert/llm-convert/#palimpzest.query.operators.convert.LLMConvertBonded","title":"LLMConvertBonded","text":"<p>               Bases: <code>LLMConvert</code></p>"},{"location":"api/operators/convert/llm-convert/#palimpzest.query.operators.convert.LLMConvertBonded.convert","title":"convert","text":"<pre><code>convert(\n    candidate: DataRecord, fields: list[str]\n) -&gt; tuple[dict[FieldName, list[Any]], GenerationStats]\n</code></pre>"},{"location":"api/operators/convert/mixture-of-agents-convert/","title":"MixtureOfAgentsConvert","text":""},{"location":"api/operators/convert/mixture-of-agents-convert/#palimpzest.query.operators.mixture_of_agents_convert.MixtureOfAgentsConvert","title":"MixtureOfAgentsConvert","text":"<p>               Bases: <code>LLMConvert</code></p>"},{"location":"api/operators/convert/mixture-of-agents-convert/#palimpzest.query.operators.mixture_of_agents_convert.MixtureOfAgentsConvert.__init__","title":"__init__","text":"<pre><code>__init__(\n    proposer_models: list[Model],\n    temperatures: list[float],\n    aggregator_model: Model,\n    proposer_prompt_strategy: PromptStrategy = PromptStrategy.COT_MOA_PROPOSER,\n    aggregator_prompt_strategy: PromptStrategy = PromptStrategy.COT_MOA_AGG,\n    proposer_prompt: str | None = None,\n    *args,\n    **kwargs,\n)\n</code></pre>"},{"location":"api/operators/convert/mixture-of-agents-convert/#palimpzest.query.operators.mixture_of_agents_convert.MixtureOfAgentsConvert.convert","title":"convert","text":"<pre><code>convert(\n    candidate: DataRecord, fields: list[str]\n) -&gt; tuple[dict[FieldName, list[Any]], GenerationStats]\n</code></pre>"},{"location":"api/operators/convert/non-llm-convert/","title":"NonLLMConvert","text":""},{"location":"api/operators/convert/non-llm-convert/#palimpzest.query.operators.convert.NonLLMConvert","title":"NonLLMConvert","text":"<p>               Bases: <code>ConvertOp</code></p>"},{"location":"api/operators/convert/non-llm-convert/#palimpzest.query.operators.convert.NonLLMConvert.convert","title":"convert","text":"<pre><code>convert(\n    candidate: DataRecord, fields: list[str]\n) -&gt; tuple[dict[FieldName, list[Any]], GenerationStats]\n</code></pre>"},{"location":"api/operators/convert/rag-convert/","title":"RAGConvert","text":""},{"location":"api/operators/convert/rag-convert/#palimpzest.query.operators.rag_convert.RAGConvert","title":"RAGConvert","text":"<p>               Bases: <code>LLMConvert</code></p>"},{"location":"api/operators/convert/rag-convert/#palimpzest.query.operators.rag_convert.RAGConvert.__init__","title":"__init__","text":"<pre><code>__init__(num_chunks_per_field: int, chunk_size: int = 1000, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/convert/rag-convert/#palimpzest.query.operators.rag_convert.RAGConvert.is_image_conversion","title":"is_image_conversion","text":"<pre><code>is_image_conversion() -&gt; bool\n</code></pre> <p>RAGConvert is currently disallowed on image conversions, so this must be False.</p>"},{"location":"api/operators/convert/rag-convert/#palimpzest.query.operators.rag_convert.RAGConvert.convert","title":"convert","text":"<pre><code>convert(\n    candidate: DataRecord, fields: list[str]\n) -&gt; tuple[dict[FieldName, list[Any]], GenerationStats]\n</code></pre>"},{"location":"api/operators/convert/token-reduction-convert/","title":"TokenReducedConvert","text":""},{"location":"api/operators/convert/token-reduction-convert/#palimpzest.query.operators.token_reduction_convert.TokenReducedConvert","title":"TokenReducedConvert","text":"<p>               Bases: <code>LLMConvert</code></p>"},{"location":"api/operators/convert/token-reduction-convert/#palimpzest.query.operators.token_reduction_convert.TokenReducedConvert.__init__","title":"__init__","text":"<pre><code>__init__(token_budget: float, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/convert/token-reduction-convert/#palimpzest.query.operators.token_reduction_convert.TokenReducedConvert.is_image_conversion","title":"is_image_conversion","text":"<pre><code>is_image_conversion() -&gt; bool\n</code></pre> <p>TokenReducedConvert is currently disallowed on image conversions, so this must be False.</p>"},{"location":"api/operators/filter/filter/","title":"Base","text":""},{"location":"api/operators/filter/filter/#palimpzest.query.operators.filter.FilterOp","title":"FilterOp","text":"<p>               Bases: <code>PhysicalOperator</code>, <code>ABC</code></p>"},{"location":"api/operators/filter/filter/#palimpzest.query.operators.filter.FilterOp.__init__","title":"__init__","text":"<pre><code>__init__(filter: Filter, *args, **kwargs)\n</code></pre>"},{"location":"api/operators/filter/filter/#palimpzest.query.operators.filter.FilterOp.__call__","title":"__call__","text":"<pre><code>__call__(candidate: DataRecord) -&gt; DataRecordSet\n</code></pre>"},{"location":"api/operators/filter/filter/#palimpzest.query.operators.filter.FilterOp.is_image_filter","title":"is_image_filter  <code>abstractmethod</code>","text":"<pre><code>is_image_filter() -&gt; bool\n</code></pre> <p>Return True if the filter operation processes an image, False otherwise.</p>"},{"location":"api/operators/filter/filter/#palimpzest.query.operators.filter.FilterOp.filter","title":"filter  <code>abstractmethod</code>","text":"<pre><code>filter(candidate: DataRecord) -&gt; tuple[dict[str, bool], GenerationStats]\n</code></pre> <p>This abstract method will be implemented by subclasses of FilterOp to process the input DataRecord and generate the True / False determination of whether the input record passes the filter. A dictionary mapping a \"passed_operator\" key to the T/F boolean is returned along with the GenerationStats object.</p> <p>For example, if the input DataRecord (i.e. <code>candidate</code>) contains an image of a dog, and the filter operation is supposed to filter for images with dogs, then the output would be:</p> <p>({\"passed_operator\": True}, GenerationStats(...))</p> <p>A post-condition of this method is that the \"passed_operator\" key must be present in the output dictionary, and it's value must be a boolean. If there is an error, then the value for \"passed_operator\" must be False.</p>"},{"location":"api/operators/filter/llm-filter/","title":"LLMFilter","text":""},{"location":"api/operators/filter/llm-filter/#palimpzest.query.operators.filter.LLMFilter","title":"LLMFilter","text":"<p>               Bases: <code>FilterOp</code></p>"},{"location":"api/operators/filter/llm-filter/#palimpzest.query.operators.filter.LLMFilter.__init__","title":"__init__","text":"<pre><code>__init__(\n    model: Model,\n    prompt_strategy: PromptStrategy = PromptStrategy.COT_BOOL,\n    *args,\n    **kwargs,\n)\n</code></pre>"},{"location":"api/operators/filter/llm-filter/#palimpzest.query.operators.filter.LLMFilter.is_image_filter","title":"is_image_filter","text":"<pre><code>is_image_filter() -&gt; bool\n</code></pre>"},{"location":"api/operators/filter/llm-filter/#palimpzest.query.operators.filter.LLMFilter.filter","title":"filter","text":"<pre><code>filter(candidate: DataRecord) -&gt; tuple[dict[str, bool], GenerationStats]\n</code></pre>"},{"location":"api/operators/filter/non-llm-filter/","title":"NonLLMFilter","text":""},{"location":"api/operators/filter/non-llm-filter/#palimpzest.query.operators.filter.NonLLMFilter","title":"NonLLMFilter","text":"<p>               Bases: <code>FilterOp</code></p>"},{"location":"api/operators/filter/non-llm-filter/#palimpzest.query.operators.filter.NonLLMFilter.is_image_filter","title":"is_image_filter","text":"<pre><code>is_image_filter() -&gt; bool\n</code></pre>"},{"location":"api/operators/filter/non-llm-filter/#palimpzest.query.operators.filter.NonLLMFilter.filter","title":"filter","text":"<pre><code>filter(candidate: DataRecord) -&gt; tuple[dict[str, bool], GenerationStats]\n</code></pre>"},{"location":"api/optimization/optimizer/","title":"Optimizer","text":""},{"location":"api/optimization/optimizer/#coming-soon","title":"Coming Soon!","text":""},{"location":"getting-started/installation/","title":"Installation","text":"<p>You can install the latest stable version of Palimpzest using <code>pip</code>:</p> <pre><code>$ pip install palimpzest\n</code></pre> <p>Alternatively, if you would like to install Palimpzest from source, you can clone our GitHub repo: <pre><code>$ git clone git@github.com:mitdbg/palimpzest.git\n$ cd palimpzest\n$ pip install .\n</code></pre></p>"},{"location":"getting-started/next-steps/","title":"Next Steps","text":"<p>Now that you've learned the basics of PZ, it's time to explore topics we've touched on in more detail.</p> <p>Our User Guide contains deeper dives into the most important aspects of PZ, including:</p> <ul> <li>How to read your own data (coming soon!)</li> <li>An overview of all operators in PZ (coming soon!)</li> <li>A primer on optimization (coming soon!)</li> </ul> <p>For developers who are looking to contribute to PZ, we would also encourage you to explore our full documentation as well.</p> <p>Finally, feel free to check out other resources on PZ:</p> <ul> <li>Join our Community (if you haven't already)</li> <li>PalimpChat (research prototype of a chat interface for PZ)</li> <li>Research (a timeline of our research papers)</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start Tutorial","text":""},{"location":"getting-started/quickstart/#creating-a-dataset","title":"Creating a Dataset","text":"<p>Let's revisit our example from the Getting Started page in more depth, starting with the first two lines: <pre><code>import palimpzest as pz\n\nemails = pz.Dataset(\"emails/\")\n</code></pre> In this example, we provide <code>pz.Dataset</code>'s constructor with the path to a local directory as input. The directory has a flat structure, with one email per file: <pre><code>emails\n\u251c\u2500\u2500 email1.txt\n\u251c\u2500\u2500 email2.txt\n...\n\u2514\u2500\u2500 email9.txt\n</code></pre> Given this flat directory, PZ will create a <code>pz.DataReader</code>, which iterates over the files in the directory at runtime.</p> What if my data isn't this simple? <p>That's perfectly fine!</p> <p>The <code>pz.DataReader</code> class can be subclassed by the user to read data from more complex sources. The user just has to:</p> <ol> <li>implement the DataReader's <code>__len__()</code> method</li> <li>implement the DataReader's <code>__getitem__()</code> method</li> </ol> <p>More details can be found in our user guide for custom DataReaders.</p> <p>The <code>pz.DataReader</code> will emit one dictionary per file to the next operator in the program. By default, each dictionary will have two keys: <code>\"contents\"</code> and <code>\"filename\"</code> which map to the file's contents and filename, respectively:</p> <pre><code>import palimpzest as pz\n\nemails = pz.Dataset(\"emails/\")\noutput = emails.run()\n\nprint(output.to_df())\n\n# This produces the following output:\n#                                             contents    filename\n# 0  Message-ID: &lt;1390685.1075853083264.JavaMail.ev...  email1.txt\n# 1  Message-ID: &lt;19361547.1075853083287.JavaMail.e...  email2.txt\n#                                                  ...         ...\n# 8  Message-ID: &lt;22163131.1075859380492.JavaMail.e...  email9.txt\n</code></pre> What is <code>output</code>? <p>The <code>output</code> in the program above has type <code>pz.DataRecordCollection</code>.</p> <p>This object contains:</p> <ol> <li>The data emitted by the PZ program</li> <li>The execution stats (i.e. cost, runtime, and quality metrics) for the entire program</li> </ol> <p>We expose the <code>pz.DataRecordCollection.to_df()</code> method to make it easy for users to get the output(s) of their program in a Pandas DataFrame. We will also expose other utility methods for processing execution statistics in the near future.</p>"},{"location":"getting-started/quickstart/#computing-new-fields","title":"Computing New Fields","text":"<p>A key feature of PZ is that it provides users with the ability to compute new fields using semantic operators. To compute new fields, users need to invoke the <code>sem_add_columns()</code> method with a list of dictionaries defining the field(s) the system should compute: <pre><code>emails = emails.sem_add_columns([\n    {\"name\": \"subject\", \"type\": str, \"desc\": \"the subject of the email\"},\n    {\"name\": \"date\", \"type\": str, \"desc\": \"the date the email was sent\"},\n])\n</code></pre> In order to fully define a field, each dictionary must have the following three keys:</p> <ol> <li><code>name</code>: the name of the field</li> <li><code>type</code>: the type of the field (one of <code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>list[str]</code>, ..., <code>list[bool]</code>)</li> <li><code>desc</code>: a short natural langague description defining what the field represents</li> </ol> <p>PZ will then use one (or more) LLM(s) to generate the field for every input to the operator (i.e. each email in this example).</p> But what is <code>sem_add_columns()</code> actually doing to generate the field(s)? <p>It depends! (and this is where PZ's optimizer comes in handy)</p> <p>Depending on the difficulty of the task and your preferred optimization objective (e.g. <code>max_quality</code>) PZ will select one implementation from a set of <code>PhysicalOperators</code> to generate your field(s).</p> <p>PZ can choose from 1,000+ possible implementations of its <code>PhysicalOperators</code>. Each operator uses one (or more) LLMs and may use techniques such as RAG, Mixture-of-Agents, Critique and Refine, etc. to produce a final output.</p> <p>For a full list of <code>PhysicalOperators</code> in PZ, please consult our documentation on Operators.</p>"},{"location":"getting-started/quickstart/#filtering-inputs","title":"Filtering Inputs","text":"<p>PZ also provides users with the ability to filter inputs using natural language. In order to apply a semantic filter, users need to invoke the <code>sem_filter()</code> method with a natural language description of the critieria they are selecting for: <pre><code>emails = emails.sem_filter(\"The email is about vacation\")\nemails = emails.sem_filter(\"The email was sent in July\")\n</code></pre> These filters will keep all emails which discuss vaction(s) and which were sent in the month of July.</p>"},{"location":"getting-started/quickstart/#optimization-and-execution","title":"Optimization and Execution","text":"<p>Finally, once we've defined our program in PZ, we can optimize and execute it in order to generate our output: <pre><code>output = emails.run(max_quality=True)\n</code></pre> The <code>pz.Dataset.run()</code> method triggers PZ's execution of the program that has been defined by applying semantic operators to <code>emails</code>. The <code>run()</code> method also takes a number of keyword arguments which can configure the execution of the program.</p> <p>In particular, users can specify one optimization objective and (optionally) one constraint:</p> <p>Optimization objectives:</p> <ul> <li><code>max_quality=True</code> (maximize output quality) </li> <li><code>min_cost=True</code> (minimize program cost)</li> <li><code>min_time=True</code> (minimize program runtime)</li> </ul> <p>Constraints:</p> <ul> <li><code>quality_threshold=&lt;float&gt;</code> (threshold in range [0, 1])</li> <li><code>cost_budget=&lt;float&gt;</code> (cost in US Dollars)</li> <li><code>time_budget=&lt;float&gt;</code> (time in seconds)</li> </ul> More Info on Constraints <p>PZ can only estimate the cost, quality, and runtime of each physical operator, therefore constraints are not guaranteed to be met. Furthermore, some constraints may be infeasible (even with perfect estimates).</p> <p>In any case, PZ will make a best effort attempt to find the optimal plan for your stated objective and constraint (if present).</p> <p>To achieve better estimates -- and thus better optimization outcomes -- please read our Optimization User Guide.</p> <p>In this example we do not provide validation data to PZ. Therefore, output quality is measured relative to the performance of a \"champion model\", i.e. the model with the highest MMLU score that is available to the optimizer.</p> <p>In our Optimization User Guide we show you how to:</p> <ol> <li>provide validation data to improve the optimizer's performance</li> <li>override the optimizer if you wish to specify, for example, the specific model to use for a given operation</li> </ol> <p>Optimization: Design Philosophy</p> <p>The optimizer is meant to help the programmer quickly get to a final program (i.e. a plan).</p> <p>In the best case, the optimizer can automatically select a plan that meets the developer's needs.</p> <p>However, in cases where it falls short, we try to make it as easy as possible for developers to iterate on changes to their plan until it achieves satisfactory performance.</p>"},{"location":"getting-started/quickstart/#examining-program-output","title":"Examining Program Output","text":"<p>Finally, once your program finishes executing you can convert its output to a Pandas DataFrame and examine the results: <pre><code>print(output.to_df(cols=[\"filename\", \"date\", \"subject\"]))\n</code></pre> The <code>cols</code> keyword argument allows you to select which columns should populate your DataFrame (if it is <code>None</code>, then all columns are selected).</p> <p>As mentioned in a note above, the <code>output</code> is a <code>pz.DataRecordCollection</code> which also contains all of the execution statistics for your program. We can use this to examine the total cost and runtime of our program: <pre><code>print(f\"Total time: {output.execution_stats.total_execution_time:.1f}\")\nprint(f\"Total cost: {output.execution_stats.total_execution_cost:.3f}\")\n</code></pre> Which will produce an output like: <pre><code>Total time: 41.7\nTotal cost: 0.081\n</code></pre></p>"},{"location":"getting-started/quickstart/#whats-next","title":"What's Next?","text":"<p>Click below to proceed to the <code>Next Steps</code>.</p>"},{"location":"user-guide/datareaders/","title":"How to Read Your Own Data","text":"<p>Coming Soon!</p> <p>In the meantime, if you have questions about how to read your own data with PZ, please send us a message on Discord.</p>"},{"location":"user-guide/operators/","title":"PZ Operator Overview","text":"<p>Coming Soon!</p> <p>In the meantime, if you have questions about how to use PZ's various operators, please send us a message on Discord.</p>"},{"location":"user-guide/optimization/","title":"Getting Started with Optimization","text":"<p>Coming Soon!</p> <p>In the meantime, if you have questions about how to use PZ's optimizer, please send us a message on Discord.</p>"},{"location":"user-guide/overview/","title":"Overview","text":"<p>Our User Guide is designed to help new users get familiar with PZ at a deeper level than our Quick Start Tutorial.</p> <p>In particular, we will provide you with a deeper understanding of:</p> <ul> <li>How to read your own data (coming soon!)</li> <li>An overview of all operators in PZ (coming soon!)</li> <li>A primer on optimization (coming soon!)</li> </ul>"}]}